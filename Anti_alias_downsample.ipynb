{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Anti-alias downsample.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyN0MacX+5G/YceUtcdA8r3v",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jyotidabass/Anti-alias-downsample/blob/main/Anti_alias_downsample.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as fun\n",
        "import numpy as np\n",
        "\n",
        "class DownSample(nn.Module):\n",
        "    \n",
        "    def __init__(self, pad_type = 'reflect', filter_size = 3, stride = 2, channels = None, pad_off = 0):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.filter_size = filter_size\n",
        "        self.stride = stride\n",
        "        self.pad_off = pad_off\n",
        "        self.channels = channels\n",
        "        self.pad_sizes = [int(1.0 * (filter_size - 1) / 2),\n",
        "                          int(np.ceil(1.0 * (filter_size - 1) / 2)),\n",
        "                          int(1.0 * (filter_size - 1) / 2),\n",
        "                          int(np.ceil(1.0 * (filter_size - 1) / 2))]\n",
        "    \n",
        "        self.pad_sizes = [pad_size + pad_off for pad_size in self.pad_sizes]\n",
        "        self.off = int((self.stride - 1) / 2.0)\n",
        "        \n",
        "        if self.filter_size == 1:\n",
        "            a = np.array([1.0])\n",
        "        elif self.filter_size == 2:\n",
        "            a = np.array([1.0, 1.0])\n",
        "        elif self.filter_size == 3:\n",
        "            a = np.array([1.0, 2.0, 1.0])\n",
        "        elif self.filter_size == 4:\n",
        "            a = np.array([1.0, 3.0, 3.0, 1.0])\n",
        "        elif self.filter_size == 5:\n",
        "            a = np.array([1.0, 4.0, 6.0, 4.0, 1.0])\n",
        "        elif self.filter_size == 6:\n",
        "            a = np.array([1.0, 5.0, 10.0, 10.0, 5.0, 1.0])\n",
        "        elif self.filter_size == 7:\n",
        "            a = np.array([1.0, 6.0, 15.0, 20.0, 15.0, 6.0, 1.0])\n",
        "            \n",
        "        filt = torch.Tensor(a[:, None] * a[None, :])\n",
        "        filt = filt / torch.sum(filt)\n",
        "        self.register_buffer('filt', filt[None, None, :, :].repeat((self.channels, 1, 1, 1)))\n",
        "        self.pad = get_pad_layer(pad_type)(self.pad_sizes)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        if self.filter_size == 1:\n",
        "            if self.pad_off == 0:\n",
        "                return x[:, :, ::self.stride, ::self.stride]\n",
        "            else:\n",
        "                return self.pad(x)[:, :, ::self.stride, ::self.stride]\n",
        "        \n",
        "        else:\n",
        "            return fun.conv2d(self.pad(x), self.filt, stride = self.stride, groups = x.shape[1])\n",
        "        \n",
        "\n",
        "def get_pad_layer(pad_type):\n",
        "    \n",
        "    if pad_type == 'reflect':\n",
        "        pad_layer = nn.ReflectionPad2d\n",
        "    elif pad_type == 'replication':\n",
        "        pad_layer = nn.ReplicationPad2d\n",
        "    else:\n",
        "        print('Pad Type [%s] not recognized' % pad_type)\n",
        "    \n",
        "    return pad_layer"
      ],
      "metadata": {
        "id": "ka3n-PSobV6A"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch.utils.data import dataset\n",
        "import torchvision.transforms as T\n",
        "from PIL import Image\n",
        "import os\n",
        "os.environ[\"KMP_DUPLICATE_LIB_OK\"]=\"TRUE\"\n",
        "\n",
        "class LoLDataset(dataset.Dataset):\n",
        "    \n",
        "    def __init__(self, low_light_root, target_root, img_size = 64):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.lol_fnames = [os.path.join(low_light_root, file) for file in os.listdir(low_light_root)]\n",
        "        self.target_fnames = [os.path.join(target_root, file) for file in os.listdir(target_root)]\n",
        "        \n",
        "        self.transform = T.Compose([T.CenterCrop((img_size, img_size)),\n",
        "                                    T.ToTensor(),\n",
        "                                    T.Normalize([0.0,0.0,0.0], [1.0,1.0,1.0])])\n",
        "        \n",
        "    def __getitem__(self, idx):\n",
        "        \n",
        "        lol = Image.open(self.lol_fnames[idx]).convert('RGB')\n",
        "        target = Image.open(self.target_fnames[idx]).convert('RGB')\n",
        "        lol = self.transform(lol)\n",
        "        target = self.transform(target)\n",
        "        \n",
        "        return lol, target\n",
        "    \n",
        "    def __len__(self):\n",
        "        \n",
        "        return len(self.lol_fnames)"
      ],
      "metadata": {
        "id": "0KSJo_oXbYI7"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "class CompressChannels(nn.Module):\n",
        "        \n",
        "    \"\"\"\n",
        "        Compresses the input channels to 2 by concatenating the results of\n",
        "        Global Average Pooling(GAP) and Global Max Pooling(GMP).\n",
        "        HxWxC => HxWx2\n",
        "    \"\"\"\n",
        "    \n",
        "    def forward(self, x):\n",
        "        \n",
        "        return torch.cat((torch.max(x, 1)[0].unsqueeze(1), torch.mean(x,1).unsqueeze(1)), dim = 1)\n",
        "\n",
        "class SpatialAttention(nn.Module):\n",
        "    \n",
        "    '''\n",
        "    Spatial Attention: \n",
        "                    HxWxC\n",
        "                      |\n",
        "                  ---------\n",
        "                  |       |\n",
        "                 GAP     GMP\n",
        "                  |       |\n",
        "                  ----C---\n",
        "                      |\n",
        "                    HxWx2\n",
        "                      |\n",
        "                    Conv\n",
        "                     |\n",
        "                  Sigmoid\n",
        "                     |\n",
        "                   HxWx1\n",
        "                   \n",
        "    Multiplying HxWx1 with input again gives output -> HxWxC\n",
        "    '''\n",
        "    \n",
        "    def __init__(self):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.compress_channels = CompressChannels()\n",
        "        self.conv = nn.Conv2d(in_channels = 2, out_channels = 1, kernel_size = 5,\n",
        "                              stride = 1, padding = 2)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        compress_x = self.compress_channels(x)\n",
        "        x_out = self.conv(compress_x)\n",
        "        scale = torch.sigmoid(x_out)\n",
        "        return x * scale\n",
        "    \n",
        "\n",
        "class ChannelAttention(nn.Module):\n",
        "    \n",
        "    '''\n",
        "    Channel Attention(Squeeze and Excitation Operation): \n",
        "                    HxWxC\n",
        "                      |       \n",
        "                     GAP     \n",
        "                      |  \n",
        "                    1x1xC\n",
        "                      |\n",
        "                 Conv + PReLU \n",
        "                      |\n",
        "                    1x1xC/r (r = reduction ratio)\n",
        "                      |\n",
        "                    Conv\n",
        "                     |\n",
        "                   1x1xC\n",
        "                     |\n",
        "                  Sigmoid\n",
        "                   \n",
        "    Multiplying 1x1xC with input again gives output -> HxWxC\n",
        "    '''\n",
        "    \n",
        "    def __init__(self, channels, r = 8, bias = True):\n",
        "        \n",
        "        super().__init__()\n",
        "        #Squeeze\n",
        "        self.squeeze = nn.AdaptiveAvgPool2d(1)\n",
        "        #excitation\n",
        "        self.excite = nn.Sequential(nn.Conv2d(channels, channels // r, kernel_size = 1,\n",
        "                                              padding = 0, bias = bias),\n",
        "                                    nn.PReLU(),\n",
        "                                    nn.Conv2d(channels // r, channels, kernel_size = 1,\n",
        "                                              padding = 0, bias = bias),\n",
        "                                    nn.Sigmoid()\n",
        "                                    )\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        out = self.squeeze(x)\n",
        "        out = self.excite(out)\n",
        "        return out * x\n",
        "\n",
        "\n",
        "class DAU(nn.Module):\n",
        "    \n",
        "    '''\n",
        "    Dual Attention Unit(DAU) :\n",
        "          --------- HxWxC\n",
        "          '            |\n",
        "          '    Conv + PReLU + Conv\n",
        "          '            |\n",
        "          '        -------- \n",
        "          '        |      |\n",
        "          '       SA     CA\n",
        "          '       |      |\n",
        "          '       -------\n",
        "          '          |\n",
        "          '       Concate\n",
        "          '          |\n",
        "          '        Conv\n",
        "          '         |\n",
        "          '---------+\n",
        "                    |\n",
        "                 Output\n",
        "                   \n",
        "    '''\n",
        "    def __init__(self, channels, kernel_size = 3, r = 8, bias = False):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.block = nn.Sequential(nn.Conv2d(channels, channels, kernel_size, padding = 1, bias = bias),\n",
        "                                   nn.PReLU(),\n",
        "                                   nn.Conv2d(channels, channels, kernel_size, padding = 1, bias = bias))\n",
        "        self.SA = SpatialAttention()\n",
        "        self.CA = ChannelAttention(channels, r, bias = bias)\n",
        "        self.conv1x1 = nn.Conv2d(channels*2, channels, kernel_size = 1, bias = bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        res = self.block(x)\n",
        "        _sa = self.SA(res)\n",
        "        _ca = self.CA(res)\n",
        "        res = torch.cat([_sa, _ca], dim = 1)\n",
        "        res = self.conv1x1(res)\n",
        "        res += x\n",
        "        return res\n",
        "    \n",
        "\n",
        "class UpsampleBlock(nn.Module):\n",
        "    \n",
        "    '''\n",
        "    \n",
        "                HxWxC----------------\n",
        "                  |                 '\n",
        "          Conv1x1 + PReLU           |\n",
        "                  |           Bilinear Upsampling\n",
        "          Conv3x3 + PReLU           |\n",
        "                 |               Conv1x1\n",
        "         Bilinear Upsampling        |\n",
        "                 |                  ' \n",
        "              Conv1x1               '\n",
        "                 |                  '\n",
        "                 +-------------------\n",
        "                 |\n",
        "            2H x 2W x C/2\n",
        "                 \n",
        "    '''\n",
        "    \n",
        "    def __init__(self, channels, bias = False):\n",
        "        \n",
        "        super().__init__()\n",
        "        \n",
        "        self.left = nn.Sequential(nn.Conv2d(channels, channels, kernel_size = 1, padding = 0, bias = bias),\n",
        "                                  nn.PReLU(),\n",
        "                                  nn.Conv2d(channels, channels, kernel_size = 3, padding = 1, bias = bias),\n",
        "                                  nn.PReLU(),\n",
        "                                  nn.Upsample(scale_factor = 2, mode = 'bilinear', align_corners = bias),\n",
        "                                  nn.Conv2d(channels, channels//2, kernel_size = 1, padding = 0, bias = bias))\n",
        "        \n",
        "        self.right = nn.Sequential(nn.Upsample(scale_factor = 2, mode = 'bilinear', align_corners = bias),\n",
        "                                  nn.Conv2d(channels, channels//2, kernel_size = 1, padding = 0, bias = bias))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        left = self.left(x)\n",
        "        right = self.right(x)\n",
        "        out = left + right\n",
        "        return out\n",
        "\n",
        "    \n",
        "class UpSample(nn.Module):\n",
        "    \n",
        "    def __init__(self, channels, scale_factor, stride = 2):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.scale_factor = int(np.log2(scale_factor))\n",
        "        modules = []\n",
        "        \n",
        "        for i in range(self.scale_factor):\n",
        "            modules.append(UpsampleBlock(channels))\n",
        "            channels = int(channels // 2)\n",
        "        \n",
        "        self.block = nn.Sequential(*modules)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        return self.block(x)\n",
        "\n",
        "    \n",
        "class DownSampleBlock(nn.Module):\n",
        "    \n",
        "    '''\n",
        "    \n",
        "                HxWxC----------------\n",
        "                  |                 '\n",
        "          Conv1x1 + PReLU           |\n",
        "                  |         Antialias Downsampling\n",
        "          Conv3x3 + PReLU           |\n",
        "                 |               Conv1x1\n",
        "         Antialias Downsampling     |\n",
        "                 |                  ' \n",
        "              Conv1x1               '\n",
        "                 |                  '\n",
        "                 +-------------------\n",
        "                 |\n",
        "            H/2 x W/2 x 2C\n",
        "                 \n",
        "    '''\n",
        "    \n",
        "    def __init__(self, channels, bias = False):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.left = nn.Sequential(nn.Conv2d(channels, channels, kernel_size = 1, padding = 0, bias = bias),\n",
        "                                  nn.PReLU(),\n",
        "                                  nn.Conv2d(channels, channels, kernel_size = 3, padding = 1, bias = bias),\n",
        "                                  nn.PReLU(),\n",
        "                                  DownSample(channels = channels, filter_size = 3, stride = 2),\n",
        "                                  nn.Conv2d(channels, channels*2, kernel_size = 1, padding = 0, bias = bias))\n",
        "        \n",
        "        self.right = nn.Sequential(DownSample(channels = channels, filter_size = 3, stride = 2),\n",
        "                                  nn.Conv2d(channels, channels*2, kernel_size = 1, padding = 0, bias = bias))\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        left = self.left(x)\n",
        "        right = self.right(x)\n",
        "        out = left + right\n",
        "        return out\n",
        " \n",
        "       \n",
        "class DownSamp(nn.Module):\n",
        "    \n",
        "    def __init__(self, channels, scale_factor, stride = 2):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.scale_factor = int(np.log2(scale_factor))\n",
        "        modules = []\n",
        "        \n",
        "        for i in range(self.scale_factor):\n",
        "            modules.append(DownSampleBlock(channels))\n",
        "            channels = int(channels * stride)\n",
        "        \n",
        "        self.block = nn.Sequential(*modules)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        return self.block(x)        \n",
        "\n",
        "\n",
        "class SKFF(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_c, r, bias = False):\n",
        "        \n",
        "        super().__init__()\n",
        "        d = max(int(in_c/r), 4)\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv = nn.Sequential(nn.Conv2d(in_c, d, kernel_size = 1, padding = 0, bias = bias),\n",
        "                                  nn.PReLU())\n",
        "        self.attention_fcs = nn.ModuleList([])\n",
        "        \n",
        "        for i in range(3):\n",
        "            self.attention_fcs.append(nn.Conv2d(d, in_c, kernel_size = 1, stride = 1, bias = bias))\n",
        "        \n",
        "        self.softmax = nn.Softmax(dim = 1)\n",
        "        \n",
        "    def forward(self, in_features):\n",
        "        \n",
        "        batch_size = in_features[0].shape[0]\n",
        "        num_features = in_features[0].shape[1]\n",
        "        \n",
        "        in_features = torch.cat(in_features, dim = 1)\n",
        "        print(in_features.shape)\n",
        "        in_features = in_features.view(batch_size, 3, num_features, in_features.shape[2], in_features.shape[3])\n",
        "        \n",
        "        features_u = torch.sum(in_features, dim = 1)\n",
        "        features_s = self.avg_pool(features_u)\n",
        "        features_z = self.conv(features_s)\n",
        "        \n",
        "        attn_vectors = [fc(features_z) for fc in self.attention_fcs]\n",
        "        attn_vectors = torch.cat(attn_vectors, dim = 1)\n",
        "        attn_vectors = attn_vectors.view(batch_size, 3, num_features, 1, 1)\n",
        "        \n",
        "        attn_vectors = self.softmax(attn_vectors)\n",
        "        features_v = torch.sum(in_features * attn_vectors, dim = 1)\n",
        "        \n",
        "        return features_v\n",
        "        \n",
        "\n",
        "class MSRB(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_features, height, width, stride, bias):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.num_features = num_features\n",
        "        self.height = height\n",
        "        self.width = width\n",
        "        \n",
        "        self.dau_blocks = nn.ModuleList([nn.ModuleList([DAU(int(num_features*stride**i))]*width) for i in range(height)])\n",
        "        \n",
        "        feats = [int((stride**i)*num_features) for i in range(height)]\n",
        "        scale = [2**i for i in range(1, height)]\n",
        "        \n",
        "        self.last_up = nn.ModuleDict()\n",
        "        for i in range(1, height):\n",
        "            self.last_up.update({f'{i}': UpSample(channels = int(num_features*stride**i), scale_factor = 2**i, stride = stride)})\n",
        "            \n",
        "        self.down = nn.ModuleDict()\n",
        "        i = 0\n",
        "        \n",
        "        scale.reverse()\n",
        "        for f in feats:\n",
        "            for s in scale[i:]:\n",
        "                self.down.update({f'{f}_{s}': DownSamp(f, s, stride)})\n",
        "            i+=1\n",
        "            \n",
        "        self.up = nn.ModuleDict()\n",
        "        i = 0\n",
        "        \n",
        "        feats.reverse()\n",
        "        for f in feats:\n",
        "            for s in scale[i:]:\n",
        "                self.up.update({f'{f}_{s}': UpSample(f, s, stride)})\n",
        "            i+=1\n",
        "            \n",
        "        self.out_conv = nn.Conv2d(num_features, num_features, kernel_size = 3, padding = 1, bias = bias)\n",
        "        self.skff_blocks = nn.ModuleList([SKFF(num_features*stride**i, height) for i in range(height)])\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        inp = x.clone()\n",
        "        out = []\n",
        "        \n",
        "        for j in range(self.height):\n",
        "            if j==0:\n",
        "                inp = self.dau_blocks[j][0](inp)\n",
        "            else:\n",
        "                inp = self.dau_blocks[j][0](self.down[f'{inp.size(1)}_{2}'](inp))\n",
        "            out.append(inp)\n",
        "            \n",
        "        for i in range(1, self.width):\n",
        "            \n",
        "            if True:\n",
        "                temp = []\n",
        "                for j in range(self.height):\n",
        "                    TENSOR = []\n",
        "                    nfeats = (2**j)*self.num_features\n",
        "                    for k in range(self.height):\n",
        "                        TENSOR.append(self.select_up_down(out[k], j, k))\n",
        "                    \n",
        "                    skff = self.skff_blocks[j](TENSOR)\n",
        "                    temp.append(skff)\n",
        "                    \n",
        "            else:\n",
        "                \n",
        "                temp = out\n",
        "                \n",
        "            for j in range(self.height):\n",
        "                \n",
        "                out[j] = self.dau_blocks[j][i](temp[j])\n",
        "                \n",
        "        output = []\n",
        "        for k in range(self.height):\n",
        "            \n",
        "            output.append(self.select_last_up(out[k], k))\n",
        "            \n",
        "        output = self.skff_blocks[0](output)\n",
        "        output = self.out_conv(output)\n",
        "        output = output + x\n",
        "        return output\n",
        "    \n",
        "    def select_up_down(self, tensor, j, k):\n",
        "        \n",
        "        if j == k:\n",
        "            return tensor\n",
        "        else:\n",
        "            diff = 2 ** np.abs(j-k)\n",
        "            if j < k:\n",
        "                return self.up[f'{tensor.size(1)}_{diff}'](tensor)\n",
        "            else:\n",
        "                return self.down[f'{tensor.size(1)}_{diff}'](tensor)\n",
        "            \n",
        "    def select_last_up(self, tensor, k):\n",
        "        \n",
        "        if k == 0:\n",
        "            return tensor\n",
        "        else:\n",
        "            return self.last_up[f'{k}'](tensor)\n",
        "        \n",
        "        \n",
        "class RRG(nn.Module):\n",
        "    \n",
        "    def __init__(self, num_features, num_MSRB, height, width, stride, bias = False):\n",
        "        \n",
        "        super().__init__()\n",
        "        modules = [MSRB(num_features, height, width, stride, bias) for _ in range(num_MSRB)]\n",
        "        modules.append(nn.Conv2d(num_features, num_features, kernel_size = 3, padding = 1, stride = 1, bias = bias))\n",
        "        self.blocks = nn.Sequential(*modules)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        out = self.blocks(x)\n",
        "        out += x\n",
        "        return out\n",
        "    \n",
        "\n",
        "class MIRNet(nn.Module):\n",
        "    \n",
        "    def __init__(self, in_c = 3, out_c = 3, num_features = 64, kernel_size = 3, stride = 2, \n",
        "                 num_MSRB = 2, num_RRG = 3, height = 3, width = 2, bias = False):\n",
        "        \n",
        "        super().__init__()\n",
        "        self.first_conv = nn.Conv2d(in_c, num_features, kernel_size, padding = 1, bias = bias)\n",
        "        modules = [RRG(num_features, num_MSRB, height, width, stride, bias) for _ in range(num_RRG)]\n",
        "        self.mir_blocks = nn.Sequential(*modules)\n",
        "        self.final_conv = nn.Conv2d(num_features, out_c, kernel_size, padding = 1, bias = bias)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        \n",
        "        out = self.first_conv(x)\n",
        "        out = self.mir_blocks(out)\n",
        "        out = self.final_conv(out)\n",
        "        out += x \n",
        "        return out\n",
        "    \n",
        "                \n",
        "if __name__ == '__main__':\n",
        "    \n",
        "    #t1 = torch.randn((1, 3, 64, 64))\n",
        "    model = MIRNet()\n",
        "    pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "    print(pytorch_total_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iD9mELV-bfD6",
        "outputId": "a129cd37-1425-4f2a-9940-e56748edc3c1"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "32212944\n"
          ]
        }
      ]
    }
  ]
}